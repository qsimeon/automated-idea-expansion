# Architecture Documentation

## Overview

The Automated Idea Expansion system uses a multi-agent AI pipeline to transform half-formed ideas into polished content. This document explains the architecture, design decisions, and implementation details.

---

## Core Architecture: Multi-Stage Pipelines

All content types follow a consistent 3-stage pattern:

```
STAGE 1: Planning
  â”œâ”€ Analyzes idea
  â”œâ”€ Decides structure, tone, sections
  â”œâ”€ Determines if images needed
  â””â”€ Creates quality rubric

STAGE 2: Generation
  â”œâ”€ Text Generation (main content)
  â””â”€ Image Generation (if needed, as subcomponents)

STAGE 3: Review
  â”œâ”€ Evaluates against quality rubric
  â”œâ”€ Provides scores by category
  â””â”€ Recommends: approve / revise / regenerate

OPTIONAL STAGE 4: Iteration
  â””â”€ Fix specific issues or regenerate (code only, for now)
```

---

## Content Types

### 1. Blog Posts (`blog_post`)

**Purpose:** Long-form articles (1000-2000 words) with optional images

**Pipeline:**
- Planning (GPT-4o-mini) â†’ decides title, sections, tone, image needs
- Generation (Claude Haiku) â†’ creates markdown + up to 3 images with captions
- Review (GPT-4o-mini) â†’ scores clarity, accuracy, engagement, image relevance

**Features:**
- Context-aware image generation (images understand blog content)
- Smart placement (intro, sections, conclusion)
- Automatic captions and alt text
- Cost-optimized model selection

**Files:**
- `src/lib/agents/creators/blog-creator-v2.ts` - Main orchestrator
- `src/lib/agents/creators/image-creator.ts` - Image subagent
- `src/lib/agents/model-factory.ts` - Model selection

### 2. Mastodon Threads (`twitter_thread`)

**Purpose:** Social media threads (5-10 posts, 500 chars each) with optional hero image

**Pipeline:**
- Planning â†’ decides hook, length, key points, hero image
- Generation â†’ creates posts + optional hero image
- Review â†’ scores hook strength, flow, engagement

**Features:**
- Character count validation (â‰¤500 per post)
- Hook optimization (first post is most important)
- Optional hero image for post #1
- Publishing to Mastodon (when configured)

**Files:**
- `src/lib/agents/creators/mastodon-creator.ts`

### 3. Code Projects (`github_repo`)

**Purpose:** Interactive code (Python/JS/TS notebooks, CLI tools, web apps)

**Pipeline (Advanced):**
- Planning (GPT-5 Nano) â†’ decides language, framework, architecture + quality rubric
- Generation (Claude Sonnet 4.5) â†’ creates all files
- Review (GPT-5 Nano) â†’ evaluates correctness, security, quality, completeness
- **Iteration Loop** (unique to code):
  - If score < 75: Fix specific files (Fixer Agent) OR regenerate all
  - Re-review after fixes
  - Maximum 5 iterations
  - Early stopping if quality acceptable

**Features:**
- Targeted fixes (only fix 1-3 files, not entire project)
- Quality rubrics with 4 dimensions
- Automatic GitHub publishing
- Cost-optimized (fixes save 60-80% vs full regeneration)

**Files:**
- `src/lib/agents/creators/code/code-creator-v2.ts` - Orchestrator
- `src/lib/agents/creators/code/planning-agent.ts` - Enhanced planning
- `src/lib/agents/creators/code/generation-agent.ts` - Code generation
- `src/lib/agents/creators/code/critic-agent.ts` - Review with actionable feedback
- `src/lib/agents/creators/code/fixer-agent.ts` - Targeted file fixes

---

## Key Design Decisions

### Decision 1: Images as Components, Not Formats

**Old Architecture:**
```
Router â†’ blog | thread | code | IMAGE âŒ
```

**New Architecture:**
```
Router â†’ blog (can include images) | thread (can include hero image) | code
```

**Why?**
- Images aren't a final deliverable format
- They're **visual enhancements** that support other formats
- Allows blogs/threads to be more expressive
- Reduces format fragmentation

### Decision 2: Multi-Stage Pipelines for All Content

**Why separate planning from generation?**
- **Better quality**: Planning forces structured thinking
- **Consistency**: Same evaluation criteria every time
- **Transparency**: User can see reasoning
- **Extensibility**: Easy to add human-in-the-loop approval

**Why add a review stage?**
- **LLMs make mistakes**: Catch bugs/errors before publishing
- **Quality gates**: Ensure minimum standards
- **Feedback loops**: Review informs fixes/regeneration

### Decision 3: Model Diversity (Not One-Size-Fits-All)

**Model Selection by Task:**
| Task | Model | Why? |
|------|-------|------|
| Planning | GPT-4o-mini | Fast, cost-effective, good at structure |
| Text Generation | Claude Haiku | Excellent writing quality |
| Image Prompts | GPT-4o-mini | Creative prompt engineering |
| Review | GPT-4o-mini | Fast, consistent evaluation |
| Coding | Claude Sonnet 4.5 | Best at code generation |

**Cost Impact:**
- Planning/Review: GPT-4o-mini is fast and cost-effective ($0.15/1M input)
- Writing: Claude Haiku quality >> GPT-4o-mini at similar cost
- Coding: Claude Sonnet worth the premium ($3/1M input)

### Decision 4: Iteration Loops (Code Only, For Now)

**Why only for code?**
- Code quality is **measurable** (syntax errors, security issues)
- Code has clear **correctness criteria**
- Blogs/threads are more subjective (human judgment needed)

**Future:** Could add iteration to blogs/threads if quality issues persist.

---

## Agent System Architecture

### Router Agent

**Responsibility:** Choose the best format for an idea

**Decision Logic:**
1. If ML/AI keywords â†’ `github_repo` (code exploration)
2. If "build X" or "implement Y" â†’ `github_repo` (tool/demo)
3. If hands-on/experimental â†’ `github_repo` (interactive value)
4. If conceptual/explanatory â†’ `blog_post`
5. If quick tips/insights â†’ `twitter_thread`
6. When uncertain â†’ prefer code (more valuable for technical ideas)

**Files:** `src/lib/agents/router-agent.ts`

### Creator Agent (Orchestrator)

**Responsibility:** Route to format-specific creator

**Flow:**
```
Creator Agent receives:
  â”œâ”€ Idea (from Judge)
  â””â”€ Format (from Router)

Routes to:
  â”œâ”€ createBlogV2() for blog_post
  â”œâ”€ createMastodonThread() for twitter_thread
  â””â”€ createCodeProjectV2() for github_repo
```

**Files:** `src/lib/agents/creator-agent.ts`

### Image Generation Subagent

**Responsibility:** Generate images as components (NOT standalone creator)

**Functions:**
- `createImagePrompt(spec, context)` - Create detailed prompt from concept + content context
- `generateImage(prompt, aspectRatio)` - Generate actual image via API
- `generateImageCaption(prompt, concept)` - Create alt text
- `generateImageForContent(spec, context)` - Complete pipeline

**API Priority:**
1. fal.ai (FLUX Schnell) - fast, generous free tier
2. Hugging Face (SDXL) - free tier
3. Replicate (FLUX) - paid but cheap

**Files:** `src/lib/agents/creators/image-creator.ts`

---

## Model Factory

**Purpose:** Centralized model selection for consistent, cost-optimized AI usage

**Supported Models:**
```typescript
type ModelType =
  | 'gpt-4o-mini'     // Fast, cost-effective ($0.15/1M input)
  | 'claude-haiku'    // Fast, excellent writing ($0.25/1M input)
  | 'claude-sonnet';  // Best coding/writing ($3/1M input)
```

**Usage:**
```typescript
import { createModel, IMAGE_PROMPT_MODEL } from './model-factory';

// Use the recommended constant for image prompts:
const model = createModel(IMAGE_PROMPT_MODEL, 0.9);

// Or be explicit:
const model = createModel('gpt-4o-mini', 0.7);
```

**Files:** `src/lib/agents/model-factory.ts`

---

## Structured Outputs with Zod

**Problem:** LLMs sometimes return invalid JSON, requiring complex parsing/validation

**Solution:** Use LangChain's `withStructuredOutput()` + Zod schemas

**Example:**
```typescript
import { z } from 'zod';

const BlogPlanSchema = z.object({
  title: z.string(),
  sections: z.array(z.string()),
  tone: z.string(),
  targetWordCount: z.number(),
  includeImages: z.boolean(),
  imageSpecs: z.array(ImageSpecSchema),
});

const model = createModel('gpt-4o-mini');
const structuredModel = model.withStructuredOutput(BlogPlanSchema);

const plan = await structuredModel.invoke(prompt);
// âœ… Guaranteed valid BlogPlan, no parsing needed!
```

**Benefits:**
- âœ… **Zero JSON parsing errors** (schema guarantees validity)
- âœ… **Type safety** (TypeScript knows the structure)
- âœ… **~340 lines of error handling removed** (compared to manual parsing)
- âœ… **Cleaner code** (no try/catch blocks for parsing)

**Used in:**
- Blog planning, draft, review
- Code planning, review
- Thread planning, draft, review

---

## Quality Rubrics

**Purpose:** Consistent, measurable evaluation criteria

**Structure:**
```typescript
interface QualityRubric {
  correctness: {
    weight: 0.4,                    // 40% of total score
    criteria: [
      "Code runs without errors",
      "All functions handle edge cases",
      "Input validation implemented"
    ]
  },
  security: { weight: 0.3, criteria: [...] },
  codeQuality: { weight: 0.2, criteria: [...] },
  completeness: { weight: 0.1, criteria: [...] }
}
```

**Scoring Method:**
1. Evaluate each criterion (0-100)
2. Calculate category score = average of criteria in that category
3. Overall score = weighted sum of category scores

**Example:**
- Correctness: 90 (3 criteria: 95, 85, 90)
- Security: 85 (2 criteria: 80, 90)
- Code Quality: 80 (4 criteria: 75, 80, 85, 80)
- Completeness: 70 (2 criteria: 65, 75)

**Overall = (90 Ã— 0.4) + (85 Ã— 0.3) + (80 Ã— 0.2) + (70 Ã— 0.1) = 84/100**

---

## Cost Analysis

### Blog Post Creation

| Stage | Model | Tokens | Cost | Duration |
|-------|-------|--------|------|----------|
| Planning | GPT-4o-mini | ~500 | $0.0002 | 2s |
| Text Generation | Claude Haiku | ~2000 | $0.003 | 5s |
| Image Generation (Ã—3) | GPT-4o-mini + fal.ai | ~600 | $0.015 | 15s |
| Review | GPT-4o-mini | ~800 | $0.0003 | 2s |
| **Total** | | ~3900 | **$0.019** | **24s** |

### Code Project Creation (with iteration)

| Scenario | Iterations | Cost | Duration |
|----------|-----------|------|----------|
| Best case (no fixes) | 0 | $0.027 | 30s |
| Average case (2 fixes) | 2 | $0.061 | 60s |
| Worst case (5 iterations) | 5 | $0.110 | 120s |

**Cost Savings from Targeted Fixes:**
- Full regeneration: $0.035 per attempt
- Targeted fix (2 files): $0.015 per attempt
- **Savings: 60-70%**

---

## Environment Variables

```bash
# AI Models
OPENAI_API_KEY=sk-...              # GPT models
ANTHROPIC_API_KEY=sk-ant-...       # Claude models

# Image Generation
FAL_KEY=...                        # fal.ai (primary)
HUGGINGFACE_API_KEY=hf_...         # Hugging Face (fallback)
REPLICATE_API_TOKEN=r8_...         # Replicate (fallback)

# Publishing
GITHUB_TOKEN=ghp_...               # For code publishing
GITHUB_USERNAME=your_username      # For GitHub repos
MASTODON_ACCESS_TOKEN=...          # For thread publishing
MASTODON_INSTANCE_URL=https://...  # Mastodon instance

# Database
NEXT_PUBLIC_SUPABASE_URL=https://...
SUPABASE_SERVICE_ROLE_KEY=...
```

---

## File Structure â†’ Implementation Map

**How the architecture maps to actual code:**

```
src/
â”œâ”€â”€ app/                              # Next.js frontend
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ ideas/route.ts            # Create/list ideas (starts here ðŸ“¥)
â”‚   â”‚   â””â”€â”€ expand/route.ts           # Trigger pipeline (ðŸš€ entry point)
â”‚   â”œâ”€â”€ page.tsx                      # Idea input UI
â”‚   â””â”€â”€ outputs/page.tsx              # View generated content
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ schemas.ts                # âœ… Cleaned! IdeaSchema only
â”‚   â”‚   â”œâ”€â”€ types.ts                  # DB interfaces (Idea, Output)
â”‚   â”‚   â”œâ”€â”€ queries.ts                # Supabase CRUD operations
â”‚   â”‚   â””â”€â”€ supabase.ts               # DB client
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                       # ðŸ§  The AI pipeline
â”‚   â”‚   â”œâ”€â”€ types.ts                  # Agent state, plans, rubrics
â”‚   â”‚   â”œâ”€â”€ model-factory.ts          # âœ… Cleaned! Model selection
â”‚   â”‚   â”œâ”€â”€ judge-agent.ts            # ðŸ“Š Pick best idea
â”‚   â”‚   â”œâ”€â”€ router-agent.ts           # ðŸŽ¯ Choose format
â”‚   â”‚   â”œâ”€â”€ creator-agent.ts          # Orchestrates format creators
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ creators/
â”‚   â”‚   â”‚   â”œâ”€â”€ blog-creator-v2.ts    # ðŸ“ 3-stage blog pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ mastodon-creator-v2.ts# ðŸ¦£ 3-stage thread pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ image-creator.ts      # ðŸŽ¨ Image generation subagent
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ code/                 # ðŸ’» Code creation (advanced)
â”‚   â”‚   â”‚       â”œâ”€â”€ types.ts          # Code-specific types
â”‚   â”‚   â”‚       â”œâ”€â”€ code-creator-v2.ts# 5-stage orchestrator
â”‚   â”‚   â”‚       â”œâ”€â”€ planning-agent.ts # Plan with quality rubrics
â”‚   â”‚   â”‚       â”œâ”€â”€ generation-agent.ts# Generate all files
â”‚   â”‚   â”‚       â”œâ”€â”€ critic-agent.ts   # Review with scoring
â”‚   â”‚   â”‚       â””â”€â”€ fixer-agent.ts    # Fix specific files
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ publishers/
â”‚   â”‚       â”œâ”€â”€ github-publisher.ts   # Publish to GitHub
â”‚   â”‚       â””â”€â”€ mastodon-publisher.ts # Publish threads
â”‚   â”‚
â”‚   â””â”€â”€ logging/
â”‚       â””â”€â”€ logger.ts                 # Centralized logger with context
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ ARCHITECTURE.md               # ðŸ‘ˆ This file (complete guide)
    â””â”€â”€ README.md                     # Quick start

```

**The Pipeline Flow Through Files:**

```
1. User creates idea
   â””â”€ app/page.tsx â†’ api/ideas/route.ts â†’ db/queries.ts

2. User clicks "Expand"
   â””â”€ api/expand/route.ts (ðŸ“¥) creates logger, starts pipeline

3. Judge selects best idea
   â””â”€ agents/judge-agent.ts (ðŸ“Š) evaluates all pending ideas

4. Router chooses format
   â””â”€ agents/router-agent.ts (ðŸŽ¯) decides blog/thread/code

5. Creator orchestrates format-specific pipeline
   â””â”€ agents/creator-agent.ts routes to:
      â”œâ”€ creators/blog-creator-v2.ts (ðŸ“)
      â”œâ”€ creators/mastodon-creator-v2.ts (ðŸ¦£)
      â””â”€ creators/code/code-creator-v2.ts (ðŸ’»)

6. Save output
   â””â”€ db/queries.ts stores generated content

7. User views result
   â””â”€ app/outputs/page.tsx displays notebook
```

---

## Logging Architecture

### Logger Utility

The system uses a centralized `Logger` class for consistent, traceable logging across all agents.

**Location:** `src/lib/logging/logger.ts`

**Features:**
- Execution ID generation and tracking
- ISO timestamps on all logs
- Context propagation (userId, ideaId, stage, subStage)
- Token usage tracking
- Stage duration measurement
- Child logger creation for sub-stages

**Usage Example:**
```typescript
import { createLogger } from '@/lib/logging/logger';

const logger = createLogger({
  executionId: 'exec-abc123',
  userId: 'user-456',
  ideaId: 'idea-789',
  stage: 'blog-creator',
});

logger.info('ðŸ“‹ STAGE 1: Planning', { model: 'gpt-4o-mini' });
logger.trackTokens({ input: 500, output: 1200, model: 'gpt-4o-mini' });

const planLogger = logger.child({ subStage: 'planning' });
planLogger.info('Plan created', { sections: 5 });
```

### Log Format

**Human-Readable (Current):**
```
[2026-01-21T15:30:45.123Z] INFO  [exec-abc123] [stage/substage] Message
   key: value
   key2: value2
```

**Future: Structured JSON:**
```json
{
  "timestamp": "2026-01-21T15:30:45.123Z",
  "level": "INFO",
  "executionId": "exec-abc123",
  "userId": "user-456",
  "ideaId": "idea-789",
  "stage": "stage",
  "subStage": "substage",
  "message": "Message",
  "data": { "key": "value" }
}
```

### Log Levels

- **DEBUG:** Detailed internal state (model parameters, prompt details, schema validation)
- **INFO:** Key events (stage start/end, decisions made, metrics)
- **WARN:** Recoverable issues (API key missing, using fallback, quality score low)
- **ERROR:** Failures (exceptions, invalid state, API errors)

### Tracing Executions

Each pipeline run gets a unique execution ID (e.g., `exec-abc123`). To trace a specific run:

1. Find the execution ID from the first log line
2. Filter/search logs for that ID
3. Follow the progression:
   ```
   [api-endpoint] â†’ [judge-agent] â†’ [router-agent] â†’ [creator] â†’ [api-endpoint]
   ```

### Context Propagation

The logger is passed through the LangGraph state, making it available to all agents:

**Flow:**
```
API Endpoint creates logger
    â†“
Graph receives logger in initial state
    â†“
Judge Agent: logger.child({ stage: 'judge-agent' })
    â†“
Router Agent: logger.child({ stage: 'router-agent' })
    â†“
Creator Agent: logger.child({ stage: 'creator-agent' })
    â†“
Format-specific creator: createLogger({ ideaId, stage: 'blog-creator' })
```

### Token Tracking

Each stage tracks LLM token usage:

```typescript
// After LLM call
logger.trackTokens({
  input: 500,
  output: 1200,
  model: 'gpt-4o-mini',
  cost: 0.00025  // optional
});

// At pipeline end
const totalTokens = logger.getTotalTokens();
// Returns: { input: 2500, output: 5600, total: 8100 }
```

### Performance Metrics

Each logger tracks execution duration:

```typescript
const logger = createLogger({ stage: 'blog-creator' });
// ... work happens ...
const duration = logger.getDuration();  // milliseconds since creation
```

### Emoji Quick Reference

Logs use emojis for quick visual scanning. Here are the key ones:

**Pipeline Flow:**
- ðŸ“¥ Request received (API) â†’ ðŸš€ Pipeline starting â†’ ðŸ“Š Judging ideas â†’ ðŸŽ¯ Routing format
- ðŸ“ Blog creation | ðŸ¦£ Thread creation | ðŸ’» Code creation

**Creator Stages:**
- ðŸ“‹ Planning â†’ ðŸ› ï¸ Generation â†’ ðŸ” Review â†’ ðŸ”„ Iteration (code only)
- ðŸŽ¨ Image generation (within blogs/threads)

**Status:**
- âœ… Success | âŒ Error | âš ï¸ Warning | ðŸ’¾ Saved
- ðŸ’° Token usage | ðŸ› Issues found

**Pro tip:** Search logs by emoji to jump to specific stages (e.g., search "ðŸ”" to see all reviews).

---

## Output Structure

All generated content follows a **cell-based notebook format**, inspired by Jupyter notebooks. This makes outputs:
- **Structured**: Clear separation of content types
- **Portable**: Easy to transform to different formats
- **Traceable**: Each cell has metadata

**Cell Types:**
```typescript
// Markdown cells: Headers, paragraphs, lists, quotes
{ cellType: 'markdown', blocks: [...] }

// Code cells: Executable code lines
{ cellType: 'code', language: 'python', lines: [...] }

// Image cells: Generated images with captions
{ cellType: 'image', url: '...', caption: '...', alt: '...' }
```

**Philosophy: "Atoms, not strings"**
Instead of dumping raw markdown, the LLM must structure content into atomic blocks (h1, h2, paragraph, bulletList, etc.). This forces better structure and makes validation easy.

**Files:** `src/lib/db/types.ts` (output interfaces), `src/lib/agents/types.ts` (creator schemas)

---

## Testing

### Manual Testing

1. **Test Blog Creation:**
```bash
# Create idea
curl -X POST http://localhost:3000/api/ideas \
  -H 'Content-Type: application/json' \
  -d '{"content": "The Psychology of Color in UI Design"}'

# Trigger expansion
curl -X POST http://localhost:3000/api/expand \
  -H 'Content-Type: application/json' \
  -d '{"ideaId": "..."}'
```

2. **Test Code Creation:**
```bash
# Create code-oriented idea
curl -X POST http://localhost:3000/api/ideas \
  -H 'Content-Type: application/json' \
  -d '{"content": "Build a sentiment analysis tool using transformers"}'

# Trigger expansion (should route to github_repo)
curl -X POST http://localhost:3000/api/expand \
  -H 'Content-Type: application/json' \
  -d '{"ideaId": "..."}'
```

3. **Check Output:**
- Navigate to `http://localhost:3000/outputs`
- Click on generated output
- Verify format, quality, images (for blogs)

### Automated Testing (Future)

Suggested test cases:
- Router decision accuracy (blog vs code vs thread)
- Planning agent schema validation
- Review scoring consistency
- Image generation reliability
- Iteration loop termination

---

## Future Enhancements

### Short-term (Next 2 Weeks)
1. âœ… Add iteration loop to blog/thread creators (similar to code)
2. âœ… Create mastodon-creator-v2.ts with multi-stage pipeline
3. âœ… Add metrics dashboard (iteration counts, scores, costs)
4. âœ… Fine-tune quality rubrics based on real data

### Medium-term (Next Month)
1. Human-in-the-loop approval for plans (before generation)
2. A/B testing for different prompts/models
3. Caching for expensive operations (image generation)
4. Batch processing for multiple ideas

### Long-term (Next Quarter)
1. Custom rubrics per user/project
2. Learning from user feedback (preference learning)
3. Multi-modal outputs (video, audio, interactive demos)
4. Integration with more platforms (LinkedIn, Medium, Dev.to)

---

## Troubleshooting

### Common Issues

**Issue: "Module not found: @langchain/google-genai"**
```bash
# Fix:
npm install @langchain/google-genai --legacy-peer-deps
```

**Issue: Blog creation taking > 2 minutes**
- Expected for blogs with 3 images (image generation is slow)
- Check fal.ai API key is valid
- Consider reducing image count in planning stage

**Issue: Router always chooses github_repo**
- Check idea wording - avoid ML/AI keywords if you want blog
- Add explicit "blog post" or "article" to idea description
- Router prefers code for technical topics (by design)

**Issue: Code review scores always low**
- Check quality rubric criteria (may be too strict)
- Adjust thresholds in code-creator-v2.ts
- Review critic-agent.ts prompts

---

## Additional Resources

- **LangChain Docs:** https://js.langchain.com/docs
- **Anthropic API:** https://docs.anthropic.com/en/api/getting-started
- **Zod Schemas:** https://zod.dev/
- **Structured Outputs:** https://js.langchain.com/docs/integrations/chat/structured_output

---

**Last Updated:** January 22, 2026
**Version:** 2.1 (Consolidated Documentation + Codebase Cleanup)
